{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "# Using a pool of workers\n",
    "<hr/>\n",
    "\n",
    "In many situations we have J jobs to do and P processors available.  If each job takes $T_j$ time, it would helpful to have an automated procedure for launching jobs on processes in such a way that each process uses approximately $W_p$ total work, where\n",
    "\n",
    "\\begin{equation*}\n",
    "W_p \\approx \\frac{1}{P}\\sum_{j=1}^J T_j \\qquad p = 1,2,...,P\n",
    "\\end{equation*}\n",
    "\n",
    "The `multiprocessing` module's Pool object solves this problem.   \n",
    "\n",
    "If we have several jobs which we expect to take unequal lengths of time to process, we can use a *pool* of workers.  The advantage of this approach is that the processes will be automatically launched, and results automatically collected and returned.  The steps in launching a pool are as follows : \n",
    "\n",
    "1.  Decide on how many *tasks* should be launched (`njobs`)\n",
    "\n",
    "2.  Decide on how many *processes* should be launched (`nprocs`)\n",
    "\n",
    "3.  Define functions that should be called when defining a worker process or processes (`worker`).  \n",
    "\n",
    "4.  Launch the pool of workers.  There are two conceptual ways to launch jobs:\n",
    "\n",
    "    * Use `apply` or `apply_async`.  This will launch a single job, with a single argument, using a process from the pool.   Multiple processes can be launched with multiple calls to `apply` or `apply_async`. \n",
    "    \n",
    "    * Use `map` or `map_async`.  This will launch multiple jobs to run the same task on an  *iterable* object (array, list, zip object, and so on).  \n",
    "    \n",
    "Here are four sample codes.  The function to be applied in each case is `f`, with an array of `njobs` tuples `data`.  In each case, the Pool is defined as\n",
    "<pre><code>\n",
    "pool = multiprocessing.Pool(processes=nprocs)\n",
    "</code></pre>\n",
    "\n",
    "For all examples, the results from all processes are stored in `results`. \n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Example 1 : Blocking code using `Pool.map`\n",
    "\n",
    "<pre><code>\n",
    "# Blocks until all results are ready\n",
    "results = pool.map(func=f, iterable=data)\n",
    "</code></pre>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Example 2 : Non-blocking code using `Pool.map_async`\n",
    "Results can be processed as they become available using a `callback` function.\n",
    "\n",
    "<pre><code>\n",
    "# Non-blocking code.  Results can be processed by a callback.\n",
    "async_results = pool.map_async(func=f, iterable=data, \n",
    "    callback=cb)\n",
    "\n",
    "# Blocks until results are ready\n",
    "results = async_results.get()    \n",
    "</code></pre>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Example 3 : Blocking code using `Pool.apply`\n",
    "Code will run sequentially - probably not what we want for parallel computing!\n",
    "<html><pre><code>\n",
    "results = []\n",
    "for d in data:\n",
    "    # Blocks until job is done\n",
    "    r = pool.apply(func=worker, args=(d,))        \n",
    "    results.append(r)\n",
    "</code></pre></html>\n",
    "\n",
    "<hr/>\n",
    "\n",
    "### Example 4 :  Non-blocking code using `Pool.apply_async`\n",
    "We can use a `callback` to process the results as they become available.\n",
    "<pre><code>\n",
    "async_results = []\n",
    "for d in data:\n",
    "    # Non-blocking calls\n",
    "    r = pool.apply_async(func=f,args=(d,),callback=cb)\n",
    "    async_results.append(r)\n",
    "    \n",
    "# Blocks until results are ready \n",
    "results = [r.get() for r in async_results] \n",
    "</code></pre>\n",
    "\n",
    "Two additional examples illustrate how to distribute tasks using `chunksize` (Example 5) and how to use a callback function to process results as they become \n",
    "available (Example 6). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Sample results explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following results are typical results obtained using the `Pool.map_async` call.\n",
    "<pre><code>\n",
    "Launching 19 jobs on 8 cores\n",
    "In process 4916 ( 0) is sleeping   4.8323 seconds\n",
    "In process 4918 ( 2) is sleeping   0.0375 seconds\n",
    "In process 4921 ( 5) is sleeping   2.9111 seconds\n",
    "In process 4917 ( 1) is sleeping   2.2037 seconds\n",
    "In process 4922 ( 6) is sleeping   3.3578 seconds\n",
    "In process 4920 ( 4) is sleeping   4.6963 seconds\n",
    "In process 4919 ( 3) is sleeping   4.5549 seconds\n",
    "In process 4923 ( 7) is sleeping   0.4197 seconds\n",
    "In process 4918 ( 8) is sleeping   3.8324 seconds\n",
    "In process 4923 ( 9) is sleeping   1.1840 seconds\n",
    "In process 4923 (10) is sleeping   0.1541 seconds\n",
    "In process 4923 (11) is sleeping   3.9439 seconds\n",
    "In process 4917 (12) is sleeping   1.7304 seconds\n",
    "In process 4921 (13) is sleeping   3.1164 seconds\n",
    "In process 4922 (14) is sleeping   3.0791 seconds\n",
    "In process 4918 (15) is sleeping   0.7428 seconds\n",
    "In process 4917 (16) is sleeping   0.9155 seconds\n",
    "In process 4919 (17) is sleeping   0.5721 seconds\n",
    "In process 4918 (18) is sleeping   0.0731 seconds\n",
    "<br/>\n",
    "Total time spent in each process\n",
    "Process  1 (4916)    4.8323(s)    1 job(s) (0,)\n",
    "Process  2 (4917)    4.8496(s)    3 job(s) (1, 12, 16)\n",
    "Process  3 (4918)    4.6857(s)    4 job(s) (2, 8, 15, 18)\n",
    "Process  4 (4919)    5.1269(s)    2 job(s) (3, 17)\n",
    "Process  5 (4920)    4.6963(s)    1 job(s) (4,)\n",
    "Process  6 (4921)    6.0275(s)    2 job(s) (5, 13)\n",
    "Process  7 (4922)    6.4369(s)    2 job(s) (6, 14)\n",
    "Process  8 (4923)    5.7017(s)    4 job(s) (7, 9, 10, 11)\n",
    "\n",
    "      Total work done (s)      42.3570\n",
    "      Wall clock time (s)       6.4890\n",
    "</code></pre>\n",
    "The first set of results (19 lines) is printed for each job launched and \n",
    "provides the process PID (decided by the OS), the task number (0-18), and the time spent in each job.   This information is printed as jobs are launched. \n",
    "\n",
    "The second set of results (8 lines) collects process information and provides the processor number (1-8) and PID, the total time spent in that process, the number of jobs launched on that processor, and the job numbers launched on that processor.\n",
    "\n",
    "**Observations.** The first set of results (first 19 lines) are printed as jobs are launched and illustrates the `asynchronous` nature of the call.  Jobs do not necessarily start processing as soon as they are launched.  For example, jobs 2 and 5 are started before job 1.  On the other hand, if we were to sort this list on job number, we would see that jobs are launched on our 8 processors in order.  Here are the first several jobs taken from the top of a list sorted on job number. \n",
    "\n",
    "<pre><code>\n",
    "In process 4916 ( 0) is sleeping   4.8323 seconds\n",
    "In process 4917 ( 1) is sleeping   2.2037 seconds\n",
    "In process 4918 ( 2) is sleeping   0.0375 seconds\n",
    "In process 4919 ( 3) is sleeping   4.5549 seconds\n",
    "In process 4920 ( 4) is sleeping   4.6963 seconds\n",
    "In process 4921 ( 5) is sleeping   2.9111 seconds\n",
    "In process 4922 ( 6) is sleeping   3.3578 seconds\n",
    "In process 4923 ( 7) is sleeping   0.4197 seconds\n",
    "In process 4918 ( 8) is sleeping   3.8324 seconds\n",
    "In process 4923 ( 9) is sleeping   1.1840 seconds\n",
    "....\n",
    "</code></pre>\n",
    "The first 8 jobs (jobnums 0-7) are launched in order on processors 4916-4923, but the 9th job (jobnum=8) is launched on process 4918, the first processor available (jobs on 4916 and 4917 were still processing).  Similarly, job 10 (jobnum=9) is launched on the next avalailable processor 4923.\n",
    "\n",
    "Post-processing the results (second 8 lines), we see that to achieve approximately the same amount of time per processor (i.e. *load balancing*), jobs are distributed unequally.  To achieve an approximate time of 5s per process, processors 1 and 5 were only able to processs 1 job, whereas processors 3 and 8 were able to process 4 jobs each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Python modules used for all examples\n",
    "\n",
    "The following creates and saves the module `pool_tools.py`, used by all example.   The magic command `%%file` creates the indicated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pool_tools.py\n"
     ]
    }
   ],
   "source": [
    "%%file pool_tools.py\n",
    "from multiprocessing import Pool\n",
    "import time, os, random\n",
    "\n",
    "def worker(z):\n",
    "    jobnum, t = z    # Distribute tuple to variables.\n",
    "    id = os.getpid()\n",
    "    print(\"In process {} ({:2d}) is sleeping {:8.4f} seconds\".format(id,jobnum,t))\n",
    "    time.sleep(t)\n",
    "    return (jobnum,t,os.getpid())\n",
    "\n",
    "def print_pool_results(res,np):\n",
    "    # how much time was spent in each process? \n",
    "    pids = sorted(set([z[2] for z in res]))    # Get a unique set of PIDs\n",
    "    print(\"\")\n",
    "    print(\"Total time spent in each process\")\n",
    "    total_time = 0\n",
    "    for i,p in enumerate(pids):\n",
    "        proc_count = sum([1 for z in res if z[2] == p])\n",
    "        proc_time  = sum([z[1] for z in res if z[2] == p])\n",
    "        proc_jobs  = tuple([z[0] for z in res if z[2] == p])\n",
    "        print(\"Process {:2d} ({})  {:8.4f}(s) {:4d} job(s) {}\"\n",
    "              .format(i+1,p,proc_time,proc_count,proc_jobs))\n",
    "        total_time += proc_time\n",
    "    print(\"\")\n",
    "    print(\"{:>25s} {:12.4f}\".format(\"Total work done (s)\",total_time))                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 1 : pool.map(func=f,iterable=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 18938 ( 0) is sleeping   4.8323 seconds\n",
      "In process 18945 ( 7) is sleeping   0.4197 seconds\n",
      "In process 18943 ( 5) is sleeping   2.9111 seconds\n",
      "In process 18944 ( 6) is sleeping   3.3578 seconds\n",
      "In process 18939 ( 1) is sleeping   2.2037 seconds\n",
      "In process 18940 ( 2) is sleeping   0.0375 seconds\n",
      "In process 18942 ( 4) is sleeping   4.6963 seconds\n",
      "In process 18941 ( 3) is sleeping   4.5549 seconds\n",
      "In process 18940 ( 8) is sleeping   3.8324 seconds\n",
      "In process 18945 ( 9) is sleeping   1.1840 seconds\n",
      "In process 18945 (10) is sleeping   0.1541 seconds\n",
      "In process 18945 (11) is sleeping   3.9439 seconds\n",
      "In process 18939 (12) is sleeping   1.7304 seconds\n",
      "In process 18943 (13) is sleeping   3.1164 seconds\n",
      "In process 18944 (14) is sleeping   3.0791 seconds\n",
      "In process 18940 (15) is sleeping   0.7428 seconds\n",
      "In process 18939 (16) is sleeping   0.9155 seconds\n",
      "In process 18941 (17) is sleeping   0.5721 seconds\n",
      "In process 18940 (18) is sleeping   0.0731 seconds\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (18938)    4.8323(s)    1 job(s) (0,)\n",
      "Process  2 (18939)    4.8496(s)    3 job(s) (1, 12, 16)\n",
      "Process  3 (18940)    4.6857(s)    4 job(s) (2, 8, 15, 18)\n",
      "Process  4 (18941)    5.1269(s)    2 job(s) (3, 17)\n",
      "Process  5 (18942)    4.6963(s)    1 job(s) (4,)\n",
      "Process  6 (18943)    6.0275(s)    2 job(s) (5, 13)\n",
      "Process  7 (18944)    6.4369(s)    2 job(s) (6, 14)\n",
      "Process  8 (18945)    5.7017(s)    4 job(s) (7, 9, 10, 11)\n",
      "\n",
      "      Total work done (s)      42.3570\n",
      "      Wall clock time (s)       6.4995\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test1(data,np):\n",
    "    pool = Pool(processes=np)              \n",
    "\n",
    "    # This function blocks until results are available\n",
    "    results = pool.map(func=worker,iterable=data)\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "data = zip(range(njobs),sleep_times)    # Create list of tuples (p,t)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test1(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 2 : pool.map_async(func=f,iterable=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 18949 ( 2) is sleeping   0.0375 seconds\n",
      "In process 18953 ( 6) is sleeping   3.3578 seconds\n",
      "In process 18947 ( 0) is sleeping   4.8323 seconds\n",
      "In process 18950 ( 3) is sleeping   4.5549 seconds\n",
      "In process 18952 ( 5) is sleeping   2.9111 seconds\n",
      "In process 18951 ( 4) is sleeping   4.6963 seconds\n",
      "In process 18948 ( 1) is sleeping   2.2037 seconds\n",
      "In process 18954 ( 7) is sleeping   0.4197 seconds\n",
      "In process 18949 ( 8) is sleeping   3.8324 seconds\n",
      "In process 18954 ( 9) is sleeping   1.1840 seconds\n",
      "In process 18954 (10) is sleeping   0.1541 seconds\n",
      "In process 18954 (11) is sleeping   3.9439 seconds\n",
      "In process 18948 (12) is sleeping   1.7304 seconds\n",
      "In process 18952 (13) is sleeping   3.1164 seconds\n",
      "In process 18953 (14) is sleeping   3.0791 seconds\n",
      "In process 18949 (15) is sleeping   0.7428 seconds\n",
      "In process 18948 (16) is sleeping   0.9155 seconds\n",
      "In process 18950 (17) is sleeping   0.5721 seconds\n",
      "In process 18949 (18) is sleeping   0.0731 seconds\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (18947)    4.8323(s)    1 job(s) (0,)\n",
      "Process  2 (18948)    4.8496(s)    3 job(s) (1, 12, 16)\n",
      "Process  3 (18949)    4.6857(s)    4 job(s) (2, 8, 15, 18)\n",
      "Process  4 (18950)    5.1269(s)    2 job(s) (3, 17)\n",
      "Process  5 (18951)    4.6963(s)    1 job(s) (4,)\n",
      "Process  6 (18952)    6.0275(s)    2 job(s) (5, 13)\n",
      "Process  7 (18953)    6.4369(s)    2 job(s) (6, 14)\n",
      "Process  8 (18954)    5.7017(s)    4 job(s) (7, 9, 10, 11)\n",
      "\n",
      "      Total work done (s)      42.3570\n",
      "      Wall clock time (s)       6.4871\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test2(data,np):\n",
    "    pool = Pool(processes=np)              \n",
    "    \n",
    "    # This is non-blocking\n",
    "    async_results = pool.map_async(func=worker,iterable=data)\n",
    "    \n",
    "    # This call blocks until all results are available\n",
    "    results = async_results.get()   \n",
    "    \n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "data = zip(range(njobs),sleep_times)    # Create list of tuples (p,t)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test2(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 3 : pool.apply(func = f,args = data)\n",
    "\n",
    "Using this mode, jobs are launched in order and run sequentially.  Jobs are not run in parallel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 18956 ( 0) is sleeping   4.8323 seconds\n",
      "In process 18957 ( 1) is sleeping   2.2037 seconds\n",
      "In process 18958 ( 2) is sleeping   0.0375 seconds\n",
      "In process 18959 ( 3) is sleeping   4.5549 seconds\n",
      "In process 18960 ( 4) is sleeping   4.6963 seconds\n",
      "In process 18961 ( 5) is sleeping   2.9111 seconds\n",
      "In process 18962 ( 6) is sleeping   3.3578 seconds\n",
      "In process 18963 ( 7) is sleeping   0.4197 seconds\n",
      "In process 18956 ( 8) is sleeping   3.8324 seconds\n",
      "In process 18957 ( 9) is sleeping   1.1840 seconds\n",
      "In process 18958 (10) is sleeping   0.1541 seconds\n",
      "In process 18959 (11) is sleeping   3.9439 seconds\n",
      "In process 18960 (12) is sleeping   1.7304 seconds\n",
      "In process 18961 (13) is sleeping   3.1164 seconds\n",
      "In process 18962 (14) is sleeping   3.0791 seconds\n",
      "In process 18963 (15) is sleeping   0.7428 seconds\n",
      "In process 18956 (16) is sleeping   0.9155 seconds\n",
      "In process 18957 (17) is sleeping   0.5721 seconds\n",
      "In process 18958 (18) is sleeping   0.0731 seconds\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (18956)    9.5801(s)    3 job(s) (0, 8, 16)\n",
      "Process  2 (18957)    3.9598(s)    3 job(s) (1, 9, 17)\n",
      "Process  3 (18958)    0.2646(s)    3 job(s) (2, 10, 18)\n",
      "Process  4 (18959)    8.4987(s)    2 job(s) (3, 11)\n",
      "Process  5 (18960)    6.4268(s)    2 job(s) (4, 12)\n",
      "Process  6 (18961)    6.0275(s)    2 job(s) (5, 13)\n",
      "Process  7 (18962)    6.4369(s)    2 job(s) (6, 14)\n",
      "Process  8 (18963)    1.1625(s)    2 job(s) (7, 15)\n",
      "\n",
      "      Total work done (s)      42.3570\n",
      "      Wall clock time (s)      42.4936\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test3(data,np):\n",
    "    pool = Pool(processes=np)          \n",
    "\n",
    "    results = []\n",
    "    for d in data:\n",
    "        # This call is blocking;  jobs run sequentially\n",
    "        r = pool.apply(worker,args=(d,))\n",
    "        results.append(r)\n",
    "    \n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "pnum = range(njobs)\n",
    "data = zip(pnum,sleep_times)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test3(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 4 : pool.apply_async(func=data,args=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 18970 ( 3) is sleeping   4.5549 seconds\n",
      "In process 18973 ( 6) is sleeping   3.3578 seconds\n",
      "In process 18969 ( 2) is sleeping   0.0375 seconds\n",
      "In process 18967 ( 0) is sleeping   4.8323 seconds\n",
      "In process 18968 ( 1) is sleeping   2.2037 seconds\n",
      "In process 18971 ( 4) is sleeping   4.6963 seconds\n",
      "In process 18972 ( 5) is sleeping   2.9111 seconds\n",
      "In process 18974 ( 7) is sleeping   0.4197 seconds\n",
      "In process 18969 ( 8) is sleeping   3.8324 seconds\n",
      "In process 18974 ( 9) is sleeping   1.1840 seconds\n",
      "In process 18974 (10) is sleeping   0.1541 seconds\n",
      "In process 18974 (11) is sleeping   3.9439 seconds\n",
      "In process 18968 (12) is sleeping   1.7304 seconds\n",
      "In process 18972 (13) is sleeping   3.1164 seconds\n",
      "In process 18973 (14) is sleeping   3.0791 seconds\n",
      "In process 18969 (15) is sleeping   0.7428 seconds\n",
      "In process 18968 (16) is sleeping   0.9155 seconds\n",
      "In process 18970 (17) is sleeping   0.5721 seconds\n",
      "In process 18969 (18) is sleeping   0.0731 seconds\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (18967)    4.8323(s)    1 job(s) (0,)\n",
      "Process  2 (18968)    4.8496(s)    3 job(s) (1, 12, 16)\n",
      "Process  3 (18969)    4.6857(s)    4 job(s) (2, 8, 15, 18)\n",
      "Process  4 (18970)    5.1269(s)    2 job(s) (3, 17)\n",
      "Process  5 (18971)    4.6963(s)    1 job(s) (4,)\n",
      "Process  6 (18972)    6.0275(s)    2 job(s) (5, 13)\n",
      "Process  7 (18973)    6.4369(s)    2 job(s) (6, 14)\n",
      "Process  8 (18974)    5.7017(s)    4 job(s) (7, 9, 10, 11)\n",
      "\n",
      "      Total work done (s)      42.3570\n",
      "      Wall clock time (s)       6.6018\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "def test4(data,np):\n",
    "    pool = Pool(processes=np)             \n",
    "\n",
    "    # This call is non-blocking;  \n",
    "    async_results = []\n",
    "    for d in data:\n",
    "        r = pool.apply_async(worker,args = (d,))\n",
    "        async_results.append(r)\n",
    "    pool.close()\n",
    "    pool.join()     # Block here or with r.get() below\n",
    "    results = [r.get() for r in async_results]  # this blocks if pool is not closed/joined\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "pnum = range(njobs)\n",
    "data = zip(pnum,sleep_times)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test4(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 5 : Controlling how tasks are distributed\n",
    "\n",
    "We can have some control over how tasks are handed off to processors using the `chunksize` keyword.  Setting `chunksize=4` when calling `map_async` for example, the pool will put the first four tasks on the first processor, the second four tasks on the second processor, and so on.  \n",
    "\n",
    "There are two main drawbacks to this approach : \n",
    "\n",
    "* This can lead to very bad load balancing.\n",
    "* Some processors in the pool may not get used at all.\n",
    "\n",
    "In the following example, we create 23 tasks for 8 processors, with a chunksize of 4.  With this configuration, 5 processors will get 4 tasks each, 1 processor will get 3 tasks, and 2 processors will remain idle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 18976 ( 0) is sleeping   4.8323 seconds\n",
      "In process 18980 (16) is sleeping   0.9155 seconds\n",
      "In process 18978 ( 8) is sleeping   3.8324 seconds\n",
      "In process 18977 ( 4) is sleeping   4.6963 seconds\n",
      "In process 18979 (12) is sleeping   1.7304 seconds\n",
      "In process 18980 (17) is sleeping   0.5721 seconds\n",
      "In process 18980 (18) is sleeping   0.0731 seconds\n",
      "In process 18979 (13) is sleeping   3.1164 seconds\n",
      "In process 18978 ( 9) is sleeping   1.1840 seconds\n",
      "In process 18977 ( 5) is sleeping   2.9111 seconds\n",
      "In process 18976 ( 1) is sleeping   2.2037 seconds\n",
      "In process 18979 (14) is sleeping   3.0791 seconds\n",
      "In process 18978 (10) is sleeping   0.1541 seconds\n",
      "In process 18978 (11) is sleeping   3.9439 seconds\n",
      "In process 18976 ( 2) is sleeping   0.0375 seconds\n",
      "In process 18976 ( 3) is sleeping   4.5549 seconds\n",
      "In process 18977 ( 6) is sleeping   3.3578 seconds\n",
      "In process 18979 (15) is sleeping   0.7428 seconds\n",
      "In process 18977 ( 7) is sleeping   0.4197 seconds\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (18976)   11.6283(s)    4 job(s) (0, 1, 2, 3)\n",
      "Process  2 (18977)   11.3850(s)    4 job(s) (4, 5, 6, 7)\n",
      "Process  3 (18978)    9.1144(s)    4 job(s) (8, 9, 10, 11)\n",
      "Process  4 (18979)    8.6687(s)    4 job(s) (12, 13, 14, 15)\n",
      "Process  5 (18980)    1.5606(s)    3 job(s) (16, 17, 18)\n",
      "\n",
      "      Total work done (s)      42.3570\n",
      "      Wall clock time (s)      11.6860\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import  *\n",
    "\n",
    "def test5(data,np):\n",
    "    pool = Pool(processes=np)              \n",
    "\n",
    "    # This function blocks until results 'res' are available\n",
    "    async_results = pool.map_async(func=worker,iterable=data,chunksize=4)\n",
    "    results = async_results.get()\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [5*random.random() for i in range(njobs)]\n",
    "data = zip(range(njobs),sleep_times)    # Create list of tuples (p,t)\n",
    "    \n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test5(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "## Example 6 : Using a callback to process results\n",
    "\n",
    "In this example, we use a callback to process results as they become available.  Notice that results are available even before all jobs have been launched.  Also in this example, we illustrate the idea that the main program can be doing work while we are waiting for all jobs to complete. \n",
    "\n",
    "The callback takes the result returned from our worker process and computes both the total job time (`rt`) taken so far, and total wall-clock (`wc`) time.  Since we are running on multiple processors, we expect `rt` $>$ `wc`. \n",
    "\n",
    "**Note:**  For this example, we have increased the time spent in each process to some value in $[0,30]$ (rather than $[0,5]$ in previous examples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching 19 jobs on 8 cores\n",
      "In process 19002 ( 1) is sleeping  13.2220 seconds\n",
      "In process 19001 ( 0) is sleeping  28.9936 seconds\n",
      "In process 19003 ( 2) is sleeping   0.2247 seconds\n",
      "In process 19004 ( 3) is sleeping  27.3293 seconds\n",
      "In process 19005 ( 4) is sleeping  28.1781 seconds\n",
      "In process 19006 ( 5) is sleeping  17.4668 seconds\n",
      "In process 19007 ( 6) is sleeping  20.1469 seconds\n",
      "In process 19008 ( 7) is sleeping   2.5181 seconds\n",
      "---> Do some useful work while we are waiting for background jobs.\n",
      "In process 19003 ( 8) is sleeping  22.9944 seconds\n",
      "Process 19003, job  2 is done in   0.2247 (s) (wc/rt     0.27/0.22)\n",
      "In process 19008 ( 9) is sleeping   7.1043 seconds\n",
      "Process 19008, job  7 is done in   2.5181 (s) (wc/rt     2.57/2.74)\n",
      "In process 19008 (10) is sleeping   0.9244 seconds\n",
      "Process 19008, job  9 is done in   7.1043 (s) (wc/rt     9.68/9.85)\n",
      "In process 19008 (11) is sleeping  23.6632 seconds\n",
      "Process 19008, job 10 is done in   0.9244 (s) (wc/rt    10.60/10.77)\n",
      "In process 19002 (12) is sleeping  10.3827 seconds\n",
      "Process 19002, job  1 is done in  13.2220 (s) (wc/rt    13.27/23.99)\n",
      "In process 19006 (13) is sleeping  18.6984 seconds\n",
      "Process 19006, job  5 is done in  17.4668 (s) (wc/rt    17.52/41.46)\n",
      "In process 19007 (14) is sleeping  18.4745 seconds\n",
      "Process 19007, job  6 is done in  20.1469 (s) (wc/rt    20.20/61.61)\n",
      "In process 19003 (15) is sleeping   4.4566 seconds\n",
      "Process 19003, job  8 is done in  22.9944 (s) (wc/rt    23.27/84.60)\n",
      "In process 19002 (16) is sleeping   5.4927 seconds\n",
      "Process 19002, job 12 is done in  10.3827 (s) (wc/rt    23.66/94.98)\n",
      "---> Done with our other work !!!\n",
      "In process 19004 (17) is sleeping   3.4324 seconds\n",
      "Process 19004, job  3 is done in  27.3293 (s) (wc/rt    27.38/122.31)\n",
      "In process 19003 (18) is sleeping   0.4386 seconds\n",
      "Process 19003, job 15 is done in   4.4566 (s) (wc/rt    27.73/126.77)\n",
      "Process 19003, job 18 is done in   0.4386 (s) (wc/rt    28.17/127.21)\n",
      "Process 19005, job  4 is done in  28.1781 (s) (wc/rt    28.23/155.39)\n",
      "Process 19001, job  0 is done in  28.9936 (s) (wc/rt    29.04/184.38)\n",
      "Process 19002, job 16 is done in   5.4927 (s) (wc/rt    29.15/189.87)\n",
      "Process 19004, job 17 is done in   3.4324 (s) (wc/rt    30.81/193.31)\n",
      "Process 19008, job 11 is done in  23.6632 (s) (wc/rt    34.27/216.97)\n",
      "Process 19006, job 13 is done in  18.6984 (s) (wc/rt    36.22/235.67)\n",
      "Process 19007, job 14 is done in  18.4745 (s) (wc/rt    38.67/254.14)\n",
      "\n",
      "Total time spent in each process\n",
      "Process  1 (19001)   28.9936(s)    1 job(s) (0,)\n",
      "Process  2 (19002)   29.0974(s)    3 job(s) (1, 12, 16)\n",
      "Process  3 (19003)   28.1144(s)    4 job(s) (2, 8, 15, 18)\n",
      "Process  4 (19004)   30.7617(s)    2 job(s) (3, 17)\n",
      "Process  5 (19005)   28.1781(s)    1 job(s) (4,)\n",
      "Process  6 (19006)   36.1653(s)    2 job(s) (5, 13)\n",
      "Process  7 (19007)   38.6214(s)    2 job(s) (6, 14)\n",
      "Process  8 (19008)   34.2100(s)    4 job(s) (7, 9, 10, 11)\n",
      "\n",
      "      Total work done (s)     254.1418\n",
      "      Wall clock time (s)      38.7210\n"
     ]
    }
   ],
   "source": [
    "from pool_tools import *\n",
    "\n",
    "# Process results right away.\n",
    "running_total = 0\n",
    "def cb(res):\n",
    "    global t0, running_total\n",
    "    r = res\n",
    "    t1 = time.time()\n",
    "    wc = t1-t0\n",
    "    running_total += r[1]\n",
    "    print(\"Process {}, job {:2d} is done in {:8.4f} (s) (wc/rt {:8.2f}/{:.2f})\".\n",
    "          format(r[2],r[0],r[1],wc,running_total))\n",
    "\n",
    "def test6(data,np):\n",
    "    pool = Pool(processes=np)              # start 4 worker processes\n",
    "\n",
    "    # This call is non-blocking;  \n",
    "    async_results = []\n",
    "    for d in data:\n",
    "        r = pool.apply_async(func=worker, args=(d,), callback=cb)\n",
    "        async_results.append(r)\n",
    "    pool.close()\n",
    "    print(\"---> Do some useful work while we are waiting for background jobs.\")\n",
    "    time.sleep(25)\n",
    "    print(\"---> Done with our other work !!!\")\n",
    "    pool.join()     # Block here or with r.get() below\n",
    "    results = [r.get() for r in async_results]  # this blocks if pool is not closed/joined\n",
    "    print_pool_results(results,np)\n",
    "    \n",
    "np = 8\n",
    "njobs = 19\n",
    "            \n",
    "print(\"Launching {} jobs on {} cores\".format(njobs,np))\n",
    "    \n",
    "random.seed(1234)\n",
    "\n",
    "sleep_times = [30*random.random() for i in range(njobs)]\n",
    "pnum = range(njobs)\n",
    "data = zip(pnum,sleep_times)\n",
    "    \n",
    "t0 = time.time()\n",
    "tr = %timeit -n 1 -r 1 -o -q pass; test6(data,np)\n",
    "print(\"{:>25s} {:12.4f}\".format(\"Wall clock time (s)\",tr.best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
